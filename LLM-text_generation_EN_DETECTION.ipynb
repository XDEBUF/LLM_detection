{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import spacy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#from torch_geometric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:01:18.461788Z",
     "start_time": "2024-02-29T11:01:02.520165Z"
    }
   },
   "id": "ffd062eef4a11de9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Collecting en-core-web-lg==3.3.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 400.7 MB 7.0 kB/s  eta 0:00:01   |█                               | 12.9 MB 7.9 MB/s eta 0:00:49 MB 62.2 MB/s eta 0:00:06\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from en-core-web-lg==3.3.0) (3.3.0)\r\n",
      "Requirement already satisfied: setuptools in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (61.2.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.6)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.27.1)\r\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\r\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 11.3 MB 12.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: pathy>=0.3.5 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.6.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/blackswan/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.66.2)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.9.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3.0)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.7.7)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.6)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.3)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.7)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.12)\r\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.15)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (21.3)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/blackswan/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.26.4)\r\n",
      "Requirement already satisfied: jinja2 in /home/blackswan/.local/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.1.3)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.4)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.10)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/blackswan/.local/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.1.1)\r\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (5.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.26.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/blackswan/anaconda3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/blackswan/.local/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.1.5)\r\n",
      "Installing collected packages: pydantic, en-core-web-lg\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 1.9.0\r\n",
      "    Uninstalling pydantic-1.9.0:\r\n",
      "      Successfully uninstalled pydantic-1.9.0\r\n",
      "Successfully installed en-core-web-lg-3.3.0 pydantic-1.8.2\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_lg')\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_lg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T09:20:25.262542Z",
     "start_time": "2024-02-25T09:20:00.382063Z"
    }
   },
   "id": "205ce2da47c38df3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:14:31.937759Z",
     "start_time": "2024-02-29T11:14:29.656130Z"
    }
   },
   "id": "eb3fb2c8ec0c0272",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:15:04.761492Z",
     "start_time": "2024-02-29T11:14:34.983199Z"
    }
   },
   "id": "164de35a70c9f9dd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text    source  prompt_id  \\\n0  Federal law supersedes state law, and cannabis...  Bloom-7B          0   \n1  Miles feels restless after working all day. He...  Bloom-7B          0   \n2  So first of I am danish. That means that I fol...  Bloom-7B          0   \n3  In this paper we present a novel rule-based ap...  Bloom-7B          0   \n4  Most social progressives, love democracy, and ...  Bloom-7B          0   \n\n   text_length  word_count  \n0          967         157  \n1         5068         778  \n2         1602         267  \n3         5469         848  \n4         2379         380  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>source</th>\n      <th>prompt_id</th>\n      <th>text_length</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Federal law supersedes state law, and cannabis...</td>\n      <td>Bloom-7B</td>\n      <td>0</td>\n      <td>967</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Miles feels restless after working all day. He...</td>\n      <td>Bloom-7B</td>\n      <td>0</td>\n      <td>5068</td>\n      <td>778</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>So first of I am danish. That means that I fol...</td>\n      <td>Bloom-7B</td>\n      <td>0</td>\n      <td>1602</td>\n      <td>267</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In this paper we present a novel rule-based ap...</td>\n      <td>Bloom-7B</td>\n      <td>0</td>\n      <td>5469</td>\n      <td>848</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Most social progressives, love democracy, and ...</td>\n      <td>Bloom-7B</td>\n      <td>0</td>\n      <td>2379</td>\n      <td>380</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:15:12.644518Z",
     "start_time": "2024-02-29T11:15:12.615858Z"
    }
   },
   "id": "cb17acc469938f54",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788922 entries, 0 to 788921\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   text         788922 non-null  object\n",
      " 1   source       788922 non-null  object\n",
      " 2   prompt_id    788922 non-null  int64 \n",
      " 3   text_length  788922 non-null  int64 \n",
      " 4   word_count   788922 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 30.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sample.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T07:40:04.535415Z",
     "start_time": "2024-02-27T07:40:02.452010Z"
    }
   },
   "id": "5416ad2aa1b41a47",
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_train=df_sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:22:50.692772Z",
     "start_time": "2024-02-29T11:22:50.683703Z"
    }
   },
   "id": "a47430dbad641633"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "788922"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:22:52.364919Z",
     "start_time": "2024-02-29T11:22:52.359701Z"
    }
   },
   "id": "f24da4ee110964d",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['prompt_id','text_length','word_count'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:22:55.182610Z",
     "start_time": "2024-02-29T11:22:54.605515Z"
    }
   },
   "id": "58c96be047e59f4",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788922 entries, 0 to 788921\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    788922 non-null  object\n",
      " 1   source  788922 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:22:57.028788Z",
     "start_time": "2024-02-29T11:22:56.060718Z"
    }
   },
   "id": "2c97a891d036d88",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_train['source'].loc[df_train['source'] != 'Human'] = 'LLM'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:23:00.482801Z",
     "start_time": "2024-02-29T11:23:00.280195Z"
    }
   },
   "id": "5a373da0ce7fa7a9",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "LLM      441230\nHuman    347692\nName: source, dtype: int64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.source.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:23:02.353494Z",
     "start_time": "2024-02-29T11:23:02.269883Z"
    }
   },
   "id": "536e32278a8333d8",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0    Federal law supersedes state law, and cannabis...\n1    Miles feels restless after working all day. He...\n2    So first of I am danish. That means that I fol...\n3    In this paper we present a novel rule-based ap...\n4    Most social progressives, love democracy, and ...\nName: text, dtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:23:23.291622Z",
     "start_time": "2024-02-29T11:23:23.275735Z"
    }
   },
   "id": "42b780d690a0f336",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    441230\n",
      "0    347692\n",
      "Name: source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['source']=le.fit_transform(df_train['source'])\n",
    "print(df_train.source.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:23:30.806039Z",
     "start_time": "2024-02-29T11:23:30.145280Z"
    }
   },
   "id": "5e9a54bb0df31b38",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  source\n0  Federal law supersedes state law, and cannabis...       1\n1  Miles feels restless after working all day. He...       1\n2  So first of I am danish. That means that I fol...       1\n3  In this paper we present a novel rule-based ap...       1\n4  Most social progressives, love democracy, and ...       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Federal law supersedes state law, and cannabis...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Miles feels restless after working all day. He...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>So first of I am danish. That means that I fol...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In this paper we present a novel rule-based ap...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Most social progressives, love democracy, and ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:23:42.801748Z",
     "start_time": "2024-02-29T11:23:42.781898Z"
    }
   },
   "id": "691ce96011a5e1df",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/788922 [00:00<?, ?it/s]/tmp/ipykernel_5810/1402532788.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.text[i]= df_train.text[i].lower().replace(\"\\n\", \" \").strip()\n",
      "100%|██████████| 788922/788922 [1:56:50<00:00, 112.54it/s]  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df_train))):\n",
    "    df_train.text[i]= df_train.text[i].lower().replace(\"\\n\", \" \").strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:20:59.259708Z",
     "start_time": "2024-02-29T11:24:09.187667Z"
    }
   },
   "id": "d2e185d7aeda2ca2",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0    federal law supersedes state law, and cannabis...\n1    miles feels restless after working all day. he...\n2    so first of i am danish. that means that i fol...\n3    in this paper we present a novel rule-based ap...\n4    most social progressives, love democracy, and ...\nName: text, dtype: object"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:20:59.281174Z",
     "start_time": "2024-02-29T13:20:59.274942Z"
    }
   },
   "id": "a18cdc3b4b244a73",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    441230\n",
      "0    347692\n",
      "Name: source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.source.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:20:59.273542Z",
     "start_time": "2024-02-29T13:20:59.262039Z"
    }
   },
   "id": "c6b5f2278fa59207",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:22:08.502426Z",
     "start_time": "2024-02-29T13:20:59.283375Z"
    }
   },
   "id": "b49bcf073cdc2c63",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbc7a66cc4ad927e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 788922 entries, 156512 to 788921\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    788922 non-null  object\n",
      " 1   target  788922 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T16:35:55.490362Z",
     "start_time": "2024-02-25T16:35:54.968089Z"
    }
   },
   "id": "f7efc27cf2ca1be6",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#df_train=pd.read_csv(\"train.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb47d3607afe85"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, word2idx=None, nlp_model=\"en_core_web_lg\"):\n",
    "        self.nlp= spacy.load(nlp_model)\n",
    "        #self.word2idx=word2idx\n",
    "        #self.idx=len(word2idx)\n",
    "        if word2idx is None:\n",
    "            self.word2idx = {}\n",
    "            self.idx2word = {}\n",
    "            self.idx = 0\n",
    "            self.word2idx['<pad>'] = self.idx\n",
    "            self.idx2word[self.idx] = '<pad>'\n",
    "            self.idx += 1\n",
    "            self.word2idx['<unk>'] = self.idx\n",
    "            self.idx2word[self.idx] = 'unk'\n",
    "            self.idx += 1\n",
    "        else:\n",
    "            self.word2idx = word2idx\n",
    "            self.idx2word = { v:k for k,v in word2idx.items()}\n",
    "        \n",
    "    def fit_on_doc(self, doc:spacy.tokens.doc.Doc):\n",
    "        for word in doc:\n",
    "            word= str(word).lower()\n",
    "            if word not in self.word2idx:\n",
    "                self.word2idx[word]=self.idx\n",
    "                self.idx2word[self.idx]=word\n",
    "                self.idx += 1\n",
    "    def text_to_doc(self, text):\n",
    "        return self.nlp(text)\n",
    "    def doc_to_sequence(self, doc:spacy.tokens.doc.Doc):\n",
    "        sequence = []\n",
    "        for w in doc:\n",
    "            w = str(w).lower()\n",
    "            word_id = self.word2idx.get(w,-1)\n",
    "            if word_id == -1:\n",
    "                word_id = self.word2idx['<unk>']\n",
    "            sequence.append(word_id)\n",
    "        if len(sequence) == 0:\n",
    "            sequence = [0]\n",
    "        return np.array(sequence, dtype=np.int32)\n",
    "    def doc_to_adj(self, doc: spacy.tokens.doc.Doc):\n",
    "        matrix = np.zeros((len(doc),len(doc))).astype('int32')\n",
    "        for token in doc:\n",
    "            for child in token.children:\n",
    "                matrix[token.i][child.i] = 1\n",
    "                matrix[child.i][token.i] = 1\n",
    "        return matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:22:08.544032Z",
     "start_time": "2024-02-29T13:22:08.508514Z"
    }
   },
   "id": "c65b2970f99e3cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:22:10.772741Z",
     "start_time": "2024-02-29T13:22:08.548432Z"
    }
   },
   "id": "66332a6b12a9f66e"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'<pad>': 0, '<unk>': 1}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word2idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:22:10.779969Z",
     "start_time": "2024-02-29T13:22:10.774716Z"
    }
   },
   "id": "4b6c51ec46eaf829"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788922/788922 [23:24:59<00:00,  9.36it/s]     \n"
     ]
    }
   ],
   "source": [
    "train_idx2graph = {}\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    text = df_train.text[i]\n",
    "    doc = tokenizer.text_to_doc(text)\n",
    "    tokenizer.fit_on_doc(doc)\n",
    "    adj_matrix = tokenizer.doc_to_adj(doc)\n",
    "    coo = coo_matrix(adj_matrix)\n",
    "    train_idx2graph[i] = np.array([coo.row, coo.col])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:47:10.366998Z",
     "start_time": "2024-02-29T13:22:10.785187Z"
    }
   },
   "id": "58d15c229ef17f39"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "788922"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx2graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:47:10.376915Z",
     "start_time": "2024-03-01T12:47:10.371011Z"
    }
   },
   "id": "7a81d59021bc9567",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def load_word_vec(path, word2idx=None, embed_dim=300):\n",
    "    fin = open(path, 'r', encoding='utf8', newline='\\n', errors='ignore')\n",
    "    word_vec = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split()\n",
    "        word, vec = ' '.join(tokens[:-embed_dim]), tokens[-embed_dim:]\n",
    "        if word in word2idx.keys():\n",
    "            word_vec[word] = np.array(vec, dtype=np.float32)\n",
    "    return word_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:47:10.383770Z",
     "start_time": "2024-03-01T12:47:10.378243Z"
    }
   },
   "id": "9cf45baec8e2bdc1"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\n",
    "def build_embedding_matrix(word2idx, embed_dim=300):\n",
    "    embedding_matrix = np.zeros((len(word2idx), embed_dim))\n",
    "    embedding_matrix[1, :] = np.random.uniform(-1/np.sqrt(embed_dim), 1/np.sqrt(embed_dim), (1, embed_dim))\n",
    "\n",
    "    glob_vector='./glove.840B.300d.txt'\n",
    "    word_vec = load_word_vec(glob_vector, word2idx=word2idx, embed_dim=embed_dim)\n",
    "\n",
    "    for word, i in word2idx.items():\n",
    "        vec = word_vec.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[i] = vec\n",
    "    return embedding_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:47:10.391051Z",
     "start_time": "2024-03-01T12:47:10.385417Z"
    }
   },
   "id": "3c2cc7faf4deb8a4"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "embedding_matrix = build_embedding_matrix(tokenizer.word2idx, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:19.072550Z",
     "start_time": "2024-03-01T12:47:10.392737Z"
    }
   },
   "id": "aeb509f01431e26d"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.05307571 -0.03220903 -0.05218866 ...  0.02238716  0.02602542\n",
      "   0.03051941]\n",
      " [-0.27522999 -0.38723001  0.31626999 ... -0.37702     0.033019\n",
      "   0.27742001]\n",
      " ...\n",
      " [ 0.37158999 -0.51006001 -0.01041    ...  0.85096997 -0.19427\n",
      "  -0.2895    ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:19.115684Z",
     "start_time": "2024-03-01T12:48:19.092267Z"
    }
   },
   "id": "8f6fd16c757e449a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n"
     ]
    }
   ],
   "source": [
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:50.819705Z",
     "start_time": "2024-03-01T12:48:19.117367Z"
    }
   },
   "id": "8d09fa896db236a6",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1    441230\n0    347692\nName: source, dtype: int64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.source.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:50.842141Z",
     "start_time": "2024-03-01T12:48:50.821605Z"
    }
   },
   "id": "50b287b64e8af55e",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv \n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.loader import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:56.353366Z",
     "start_time": "2024-03-01T12:48:50.845019Z"
    }
   },
   "id": "d8f2c83ddf18b4f0",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:56.371320Z",
     "start_time": "2024-03-01T12:48:56.358288Z"
    }
   },
   "id": "7c0db5be20a9f17a",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "\n",
    "class TrainGraphFactoryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return \"./\"\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return os.path.join(self.root, \"train_processed\")\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train-graph.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        data_list = self.read_data()\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def read_data(self):\n",
    "        global df_train\n",
    "        df_train_data = df_train\n",
    "        all_data = []\n",
    "        for i in tqdm(range(df_train_data.shape[0])):\n",
    "            text = df_train_data.text[i]\n",
    "            doc = tokenizer.text_to_doc(text)\n",
    "            input_ids = tokenizer.doc_to_sequence(doc)\n",
    "            label = df_train_data.loc[i, [\"source\"]].to_list()\n",
    "\n",
    "            x = torch.tensor(input_ids.reshape((-1, 1)), dtype=torch.int32)\n",
    "            edge_index  = torch.tensor(train_idx2graph[i], dtype=torch.long)\n",
    "            y = torch.tensor(np.array(label), dtype=torch.float32).reshape(-1, 1)\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "            all_data.append(data)\n",
    "        return all_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:48:56.409008Z",
     "start_time": "2024-03-01T12:48:56.375498Z"
    }
   },
   "id": "7dbf33bdbc239cc"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|██████████| 788922/788922 [21:53:54<00:00, 10.01it/s]    \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainGraphFactoryDataset(root='./')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T10:45:13.400975Z",
     "start_time": "2024-03-01T12:48:56.413137Z"
    }
   },
   "id": "a443b48f678c44ae"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train.csv'] ['./train_processed/train-graph.pt']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.raw_paths, train_dataset.processed_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T10:45:14.133266Z",
     "start_time": "2024-03-02T10:45:13.677432Z"
    }
   },
   "id": "6caa5444ee9f7eac"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[315, 1], edge_index=[2, 602], y=[1, 1])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T10:45:14.777834Z",
     "start_time": "2024-03-02T10:45:14.143231Z"
    }
   },
   "id": "26107ba0224ae5bf"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[20000].y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T10:45:15.216631Z",
     "start_time": "2024-03-02T10:45:14.788214Z"
    }
   },
   "id": "6d22b72b45e187db"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "788922"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T10:45:15.246306Z",
     "start_time": "2024-03-02T10:45:15.226252Z"
    }
   },
   "id": "e27624f631db3d65"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631137 78893 78892\n"
     ]
    }
   ],
   "source": [
    "dataset = train_dataset.shuffle()\n",
    "ratio_cut= 0.8\n",
    "ratio_valid= 0.1\n",
    "train_len = int(ratio_cut*len(dataset))\n",
    "valid_len = len(dataset)-int(ratio_valid*len(dataset))\n",
    "train_dataset= dataset[:train_len]\n",
    "val_dataset= dataset[train_len:valid_len]\n",
    "test_dataset = dataset[valid_len:]\n",
    "print(len(train_dataset),len(val_dataset), len(test_dataset))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T10:45:15.781762Z",
     "start_time": "2024-03-02T10:45:15.251923Z"
    }
   },
   "id": "f95513799a83f2e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:45:15.786025Z"
    }
   },
   "id": "99d3f8e1bdd7e8e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(embedding_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:45:15.979945Z"
    }
   },
   "id": "cec664fc9ca8d04a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid = []\n",
    "invalid = []\n",
    "for data in tqdm(train_loader):\n",
    "    try:\n",
    "        if data.validate():\n",
    "            valid.append(data)\n",
    "        else:\n",
    "            invalid.append(i)\n",
    "    except ValueError as ie:\n",
    "        print('error in train edge index')\n",
    "\n",
    "\n",
    "val_valid = []\n",
    "val_invalid = []\n",
    "for  data in tqdm(val_loader):\n",
    "    try:\n",
    "        if data.validate():\n",
    "            val_valid.append(data)\n",
    "        else:\n",
    "            val_invalid.append(i)\n",
    "    except IndexError as ie:\n",
    "        print('error in val edge index')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:45:16.299107Z"
    }
   },
   "id": "1bb487921a91bd38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(len(valid)/len(train_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:19.816544Z"
    }
   },
   "id": "e2a79e6d80ea3b6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(len(invalid)/len(train_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:19.832413Z"
    }
   },
   "id": "f88c89f1ed7b008b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(len(val_valid)/len(val_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:19.851188Z"
    }
   },
   "id": "1a87477394de99d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(len(val_invalid)/len(val_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:19.864848Z"
    }
   },
   "id": "fdb620f65535eabd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "class FeedbackModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix):\n",
    "\n",
    "        super(FeedbackModel, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n",
    "        # GCNConv SAGEConv ResGatedGraphConv GraphConv(300, 128) \n",
    "        # TransformerConv GATv2Conv GATConv(300, 128, heads=4) ChebConv(300, 128, K=2)\n",
    "        # GCNConv SAGEConv ResGatedGraphConv GraphConv(128, 64) \n",
    "        # TransformerConv  GATv2Conv GATConv(4*128, 64) ChebConv(128, 64, K=2)\n",
    "        #         self.gru = nn.GRU(256, 256, num_layers=1, \n",
    "        #                           dropout=0, batch_first=True,\n",
    "        #                           bidirectional=False)          # RNN, GRU\n",
    "        # output: (N, L, D∗Hout), D = 2 if bidirectional=True otherwise 1\n",
    "        # h_n: (D∗num_layers, N, Hout)\n",
    "        self.gc1   = GATv2Conv(300, 128, heads=4)\n",
    "        #self.gc1   = GraphSAGE (300,128, 32)\n",
    "        self.pool1 = pyg_nn.TopKPooling(128, ratio=0.8)\n",
    "        self.gc2   = GCNConv(128, 64)\n",
    "        self.pool2 = pyg_nn.TopKPooling(64, ratio=0.8)\n",
    "        self.lin1  = nn.Linear(64,32)\n",
    "        self.lin2  = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data_list = [Data(x=x_, edge_index=data.edge_index, sample_batched=data.batch) for x_ in (data.x)]\n",
    "        batch = Batch.from_data_list(data_list)\n",
    "        print('(Data List Loaded)')\n",
    "        x = batch.x\n",
    "        sample_batch=batch.sample_batched\n",
    "        #x.squeeze(1)\n",
    "        #print('(squeeze passed)')\n",
    "        x = torch.clamp(x, 0, self.embed.num_embeddings - 1)\n",
    "        print('(embed 1 pre-Loaded')\n",
    "        x = self.embed(x)\n",
    "    \n",
    "        print('(Layer 1 pre-Loaded)')\n",
    "        x = F.relu(self.gc1(x, edge_index=batch.edge_index))\n",
    "        print('(Layer 1 Loaded)')\n",
    "        x, edge_index, edge_attr, batch2, perm, score = self.pool1(x, batch.edge_index, None, sample_batch)\n",
    "        x1 = torch.cat([pyg_nn.global_max_pool(x, batch2), pyg_nn.global_mean_pool(x, batch2)], dim=1)\n",
    "\n",
    "        x = F.relu(self.gc2(x, batch.edge_index))\n",
    "        print('(Layer 2 Loaded)')\n",
    "        x, edge_index, edge_attr, batch2, perm, score = self.pool2(x, data.edge_index, None, sample_batch)\n",
    "        x2 = torch.cat([pyg_nn.global_max_pool(x, batch2), pyg_nn.global_mean_pool(x, batch2)], dim=1)\n",
    "\n",
    "        x = x1 + x2\n",
    "        output = F.relu(self.lin1(x))\n",
    "        print('(Layer 3 Loaded)')\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        output = F.relu(self.lin2(x))\n",
    "        print('(outputs loaded)')\n",
    "        return output\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:19.881927Z"
    }
   },
   "id": "737cff2ae4ddf4b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = FeedbackModel(embedding_matrix)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:19.934264Z"
    }
   },
   "id": "326ac578eea20f61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=6)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:20.641608Z"
    }
   },
   "id": "d6aebbf0337cc59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "for epoch_num in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    print(f'epoch: {epoch_num} in progress...')\n",
    "    print(f'train computing')\n",
    "    \n",
    "    for sample_batched in tqdm(valid):\n",
    "        print('in train loop')\n",
    "        sample_batched = sample_batched.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sample_batched)\n",
    "        print('outputs loaded')\n",
    "        label = sample_batched.y.to(device)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        total_loss_train += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    \n",
    "    print(f'train evaluating')\n",
    "    with torch.no_grad():\n",
    "        for sample_batched in tqdm(val_valid):\n",
    "                sample_batched = sample_batched.to(device)\n",
    "                outputs = model(sample_batched)\n",
    "                label = sample_batched.y.to(device)\n",
    "                loss = criterion(outputs, label)\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "    scheduler.step(total_loss_val / len(val_dataset))\n",
    "\n",
    "    print(f'Epoch: %02.0f ended | Train Loss: {total_loss_train / len(train_dataset): .3f} | Val Loss: {total_loss_val / len(val_dataset): .3f}' % (epoch_num + 1))\n",
    "    total_loss.append([total_loss_train / len(train_dataset), total_loss_val / len(val_dataset)])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-02T10:51:20.673325Z"
    }
   },
   "id": "9f8e679ac0c6a8be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e561d65625119b3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
