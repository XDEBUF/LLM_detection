{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:21.926141889Z",
     "start_time": "2024-02-10T19:47:20.756161380Z"
    }
   },
   "id": "ffd062eef4a11de9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:25.596148797Z",
     "start_time": "2024-02-10T19:47:21.809649080Z"
    }
   },
   "id": "3d22b057bb4e12fd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#df_sample = pd.read_csv('data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:25.597014617Z",
     "start_time": "2024-02-10T19:47:25.527531790Z"
    }
   },
   "id": "164de35a70c9f9dd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:54.738299973Z",
     "start_time": "2024-02-10T19:47:25.539914435Z"
    }
   },
   "id": "a47430dbad641633"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                               text  target\n0      156512  There is a saying in my home that goes, \"You t...       0\n1      156513  Williams-Sonoma: Strategies and Future Prospec...       0\n2      156514  Shristi, your first two paragraphs are irrelev...       0\n3      156515  Extended Lifespan and Its Great Danger Essay\\n...       0\n4      156516  Imperialism and Nationalism in Middle Eastern ...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>156512</td>\n      <td>There is a saying in my home that goes, \"You t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>156513</td>\n      <td>Williams-Sonoma: Strategies and Future Prospec...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>156514</td>\n      <td>Shristi, your first two paragraphs are irrelev...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>156515</td>\n      <td>Extended Lifespan and Its Great Danger Essay\\n...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>156516</td>\n      <td>Imperialism and Nationalism in Middle Eastern ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:54.814520885Z",
     "start_time": "2024-02-10T19:47:54.740321018Z"
    }
   },
   "id": "fbc7a66cc4ad927e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_train_idx2graph=pd.read_csv('train_idx2graph.csv').reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:57.903885779Z",
     "start_time": "2024-02-10T19:47:54.786387584Z"
    }
   },
   "id": "402e23b99124effd"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_train_idx2graph=df_train_idx2graph['1']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:57.904684159Z",
     "start_time": "2024-02-10T19:47:57.903319287Z"
    }
   },
   "id": "2e7ef7dada48e551"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0    [[  0   1   1 ... 297 297 298]\\n [  1   0   3 ...\n1    [[   0    1    2 ... 1105 1105 1106]\\n [   2  ...\n2    [[  0   0   0   1   2   3   4   5   5   5   5 ...\n3    [[   0    1    1 ... 1435 1436 1437]\\n [   1  ...\n4    [[   0    0    0 ... 1643 1643 1644]\\n [   1  ...\nName: 1, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_idx2graph.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:57.915583813Z",
     "start_time": "2024-02-10T19:47:57.904472054Z"
    }
   },
   "id": "d75f5ca92eb3e5fd"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_idx2graph=df_train_idx2graph.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:57.915975150Z",
     "start_time": "2024-02-10T19:47:57.905647443Z"
    }
   },
   "id": "3569951acc443d97"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['[[  0   1   1 ... 297 297 298]\\n [  1   0   3 ... 295 296 281]]',\n       '[[   0    1    2 ... 1105 1105 1106]\\n [   2    2    0 ... 1103 1104 1101]]',\n       '[[  0   0   0   1   2   3   4   5   5   5   5   6   6   6   7   7   8   8\\n    9  10  11  11  11  12  13  14  14  14  15  15  16  17  17  18  19  19\\n   19  19  19  20  21  22  22  22  22  23  23  24  25  26  26  26  26  27\\n   28  29  30  30  30  30  31  32  32  32  32  32  33  34  34  35  36  36\\n   36  37  38  39  40  41  42  42  42  42  42  42  42  42  42  42  43  44\\n   44  44  45  45  46  46  47  47  48  49  49  50  51  52  52  52  52  53\\n   54  54  55  56  57  58  59  60  60  60  60  61  61  62  63  63  64  64\\n   64  65  66  67  67  68  69  70  70  70  70  70  71  72  72  72  73  74\\n   75  75  76  77  77  77  77  77  78  78  79  80  81  81  82  83  83  83\\n   83  84  85  86  87  88  88  88  88  88  88  88  89  90  91  91  92  92\\n   93  94  94  95  96  96  97  97  98  99  99  99 100 101 102 102 102 103\\n  104 105 105 105 105 105 106 107 108 109 109 109 109 109 110 111 111 111\\n  112 113 113 113 114 115 115 116 117 117 118 118 118 118 119 119 120 120\\n  120 121 122 123 123 123 124 125 126 126 127 127 127 127 128 128 129 130\\n  130 130 131 131 132 133 133 133 134 135 136 137 138 139 139 139 139 139\\n  140 141 141 142 142 142 143 144 145 146 147 148 148 149 150 151 152 152\\n  152 152 152 152 152 152 152 153 154 154 155 156 156 157 158 158 158 158\\n  159 160 160 160 161 161 162 163 163 164 165 165 166 166 167 168 169 170\\n  170 170 170 170 171 171 172 173 173 173 174 174 175 176 177 177 177 178\\n  179 180 180 180 180 181 182 183 183 184 185 185 185 185 186 187 188 188\\n  189 190 191 192 192 193 193 193 194 195 195 196 197 198 198 199 200 201\\n  201 201 201 201 201 201 201 202 203 204 205 205 206 206 206 206 207 208]\\n [  1   5   6   0   5   5   5   0   2   3   4   0   7  12   6   8   7  11\\n   11  11   8   9  10   6  14  13  15  65  14  19  19  18  19  17  15  16\\n   17  20  22  19  22  19  21  23  30  22  26  26  26  23  24  25  27  26\\n   30  30  22  28  29  32  32  30  31  34  35  36  34  32  33  32  32  37\\n   42  36  42  42  42  42  36  38  39  40  41  44  52  55  56  64  44  42\\n   43  45  44  46  45  47  46  49  49  47  48  52  52  42  50  51  54  54\\n   52  53  42  42  64  60  60  58  59  61  64  60  63  63  61  62  42  57\\n   60  14  67  66  70  70  70  67  68  69  72  84  72  70  71  77  77  75\\n   74  77  77  72  73  75  76  78  77  83  83  81  80  83  83  78  79  81\\n   82  70  88  88  88  85  86  87  89  91  92  95  88  91  88  90  88  94\\n   94  92  93  88  97 105  96  99  99  97  98 102 102 102  99 100 101 105\\n  105  96 103 104 109 135 109 109 109 105 106 107 108 111 111 109 110 113\\n  113 111 112 118 115 114 118 117 116 118 113 115 117 119 118 120 119 121\\n  123 120 123 120 122 127 127 126 125 127 123 124 126 128 127 130 130 128\\n  129 131 130 133 133 131 132 134 133 105 139 139 139 136 137 138 142 144\\n  141 140 142 139 141 143 142 139 152 152 148 147 152 152 152 152 145 146\\n  148 149 150 151 153 154 157 152 152 156 156 154 155 152 160 164 165 178\\n  160 158 159 161 160 163 163 161 162 158 158 166 165 170 170 170 170 166\\n  167 168 169 171 170 173 173 171 172 174 173 177 177 177 174 175 176 158\\n  180 179 181 183 184 180 183 180 182 180 186 187 188 190 185 185 185 189\\n  188 185 192 191 193 192 195 201 195 193 194 201 198 197 201 201 201 193\\n  196 198 199 200 202 206 208 201 206 205 204 206 201 203 205 207 206 201]]',\n       ...,\n       '[[  0   0   1 ... 324 324 324]\\n [  3  15   3 ... 302 322 323]]',\n       '[[  0   1   1 ... 296 297 298]\\n [  1   0   2 ... 271 271 271]]',\n       '[[  0   0   1 ... 300 300 300]\\n [  3   8   3 ... 296 297 299]]'],\n      dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx2graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:47:57.940294650Z",
     "start_time": "2024-02-10T19:47:57.906497574Z"
    }
   },
   "id": "4bc28a6599005ea5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# balanced train and test data in each df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "417bd8b9f4ebecb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ratio=0.8\n",
    "df_human= df_sample[df_sample['source']=='Human']\n",
    "df_llm = df_sample[df_sample['source']!='Human']\n",
    "df_llm.source='LLM'\n",
    "cut_idx_l=int(np.ceil(len(df_llm)*ratio))\n",
    "cut_idx_h=int(np.ceil(len(df_human)*ratio))\n",
    "df_train_human = df_human[:cut_idx_h]\n",
    "df_test_human = df_human[cut_idx_h:]\n",
    "df_train_llm = df_llm[:cut_idx_l]\n",
    "df_test_llm = df_llm[cut_idx_l:]\n",
    "df_train=pd.concat([df_train_human,df_train_llm])\n",
    "df_test=pd.concat([df_test_human,df_test_llm])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffe2703229275115"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.source.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51a27f90831d2c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df_test.source.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc9db0f6a23f44f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba60a3a667ba0ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e00a54266e786957"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7659a7ee7c6eeae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0e7cda1ba98ec74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cfa5fb19b65016d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e63c4c62d7ad899e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_lg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50385279daf10a02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(\"Apple shares rose on the news. Apple pie is delicious.\").vector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33049769ae0e6e97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4ee17862bbdecf6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### do not forget to define labels vector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21cf76eb10b1e74a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d82096068065bd4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_train['target']=le.fit_transform(df_train['source'])\n",
    "df_train.target.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b48d369f99a715"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test['target']=le.transform(df_test['source'])\n",
    "df_test.target.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91bb2b42ea9c0028"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train=df_train.drop('source', axis=1)\n",
    "df_test=df_test.drop('source',axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5619c269aea0fddb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e874ee7434028a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d237577c4bbf6db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb558cad1d1ca045"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "#from torch_geometric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:03:22.230535306Z",
     "start_time": "2024-02-10T13:02:44.344283324Z"
    }
   },
   "id": "551c6808e9811cca"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_train=train\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:16.535194044Z",
     "start_time": "2024-02-10T19:48:16.356679560Z"
    }
   },
   "id": "e40a77c5c659465b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 434666 entries, 0 to 434665\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  434666 non-null  int64 \n",
      " 1   text        434666 non-null  object\n",
      " 2   target      434666 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:17.803707791Z",
     "start_time": "2024-02-10T19:48:17.641808455Z"
    }
   },
   "id": "c3427afe5eac8d2a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_train=df_train.drop(['Unnamed: 0'], axis =1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:18.869100222Z",
     "start_time": "2024-02-10T19:48:18.771002285Z"
    }
   },
   "id": "53b891822f4e8440"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 434666 entries, 0 to 434665\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    434666 non-null  object\n",
      " 1   target  434666 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:19.680177074Z",
     "start_time": "2024-02-10T19:48:19.535784569Z"
    }
   },
   "id": "fb03e47444b3c02b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('train.csv', sep=',')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:22.642329153Z",
     "start_time": "2024-02-10T19:48:22.485425758Z"
    }
   },
   "id": "f54690ea444a1379"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, word2idx=None, nlp_model=\"en_core_web_lg\"):\n",
    "        self.nlp= spacy.load(nlp_model)\n",
    "        #self.word2idx=word2idx\n",
    "        #self.idx=len(word2idx)\n",
    "        if word2idx is None:\n",
    "            self.word2idx = {}\n",
    "            self.idx2word = {}\n",
    "            self.idx = 0\n",
    "            self.word2idx['<pad>'] = self.idx\n",
    "            self.idx2word[self.idx] = '<pad>'\n",
    "            self.idx += 1\n",
    "            self.word2idx['<unk>'] = self.idx\n",
    "            self.idx2word[self.idx] = 'unk'\n",
    "            self.idx += 1\n",
    "        else:\n",
    "            self.word2idx = word2idx\n",
    "            self.idx2word = { v:k for k,v in word2idx.items()}\n",
    "        \n",
    "    def fit_on_doc(self, doc:spacy.tokens.doc.Doc):\n",
    "        for word in doc:\n",
    "            word= str(word).lower()\n",
    "            if word not in self.word2idx:\n",
    "                self.word2idx[word]=self.idx\n",
    "                self.idx2word[self.idx]=word\n",
    "                self.idx += 1\n",
    "    def text_to_doc(self, text):\n",
    "        return self.nlp(text)\n",
    "    def doc_to_sequence(self, doc:spacy.tokens.doc.Doc):\n",
    "        sequence = []\n",
    "        for w in doc:\n",
    "            w = str(w).lower()\n",
    "            word_id = self.word2idx.get(w,-1)\n",
    "            if word_id == -1:\n",
    "                word_id = self.word2idx['<unk>']\n",
    "            sequence.append(word_id)\n",
    "        if len(sequence) == 0:\n",
    "            sequence = [0]\n",
    "        return np.array(sequence, dtype=np.int32)\n",
    "    def doc_to_adj(self, doc: spacy.tokens.doc.Doc):\n",
    "        matrix = np.zeros((len(doc),len(doc))).astype('int32')\n",
    "        for token in doc:\n",
    "            for child in token.children:\n",
    "                matrix[token.i][child.i] = 1\n",
    "                matrix[child.i][token.i] = 1\n",
    "        return matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:23.246648310Z",
     "start_time": "2024-02-10T19:48:23.163193202Z"
    }
   },
   "id": "c65b2970f99e3cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.171392396Z",
     "start_time": "2024-02-10T19:48:24.048701616Z"
    }
   },
   "id": "66332a6b12a9f66e"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{'<pad>': 0, '<unk>': 1}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word2idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.320926365Z",
     "start_time": "2024-02-10T19:48:31.216334267Z"
    }
   },
   "id": "4b6c51ec46eaf829"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.321949380Z",
     "start_time": "2024-02-10T19:48:31.217271035Z"
    }
   },
   "id": "579e55eaef902fce"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.322744312Z",
     "start_time": "2024-02-10T19:48:31.217840904Z"
    }
   },
   "id": "3e2001994a4e553b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "text      0\ntarget    0\ndtype: int64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.493585336Z",
     "start_time": "2024-02-10T19:48:31.316108714Z"
    }
   },
   "id": "30c0e06aa2233864"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "df_train=df_train[:434666]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.705544794Z",
     "start_time": "2024-02-10T19:48:31.334869655Z"
    }
   },
   "id": "5ba6d10be99445df"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "434666"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:31.774089216Z",
     "start_time": "2024-02-10T19:48:31.376291634Z"
    }
   },
   "id": "1528f28f7a2295c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_idx2graph = {}\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    text = df_train.text[i].lower().replace(\"/n\", \"\").strip()\n",
    "    doc = tokenizer.text_to_doc(text)\n",
    "    tokenizer.fit_on_doc(doc)\n",
    "    adj_matrix = tokenizer.doc_to_adj(doc)\n",
    "    coo = coo_matrix(adj_matrix)\n",
    "    train_idx2graph[i] = np.array([coo.row, coo.col])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58d15c229ef17f39"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "434666"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx2graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:36.816530511Z",
     "start_time": "2024-02-10T19:48:36.409911626Z"
    }
   },
   "id": "6d492c1b16818818"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "29c8c7fb61843a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_idx2graph = {}\n",
    "for i in tqdm(range(len(df_test))):\n",
    "    #doc=pd.concat([[df_train.text_tkn[i]],[df_test.prompt_tkn[i]])\n",
    "    tokenizer.fit_on_doc(doc)\n",
    "    adj_matrix = tokenizer.doc_to_adj(doc)\n",
    "    coo = coo_matrix(adj_matrix)\n",
    "    test_idx2graph[i] = np.array([coo.row, coo.col], dtype=np.int32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9a86467896ec5f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b78d9571da0f9d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.to_csv('test.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "992ded1a3cda7273"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result=train_idx2graph.items()\n",
    "da = list(result)\n",
    "nparr=np.array(da)\n",
    "train = pd.DataFrame(nparr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fa05bb6215b0c64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd52501cb6f9551"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.to_csv('train_idx2graph.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23704159743b1aaf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ac31f687a16291"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_idx2graph=pd.read_csv('train_idx2graph.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6928265dd0d2e21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.loadtxt('train_idx2graph.csv', usecols=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d430f8ab39a69dd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_idx2graph=df_idx2graph['1']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "836dc23bea52a31d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_idx2graph.to_numpy(dtype='float')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d690d0ef2998853a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result=test_idx2graph.items()\n",
    "da = list(result)\n",
    "nparr=np.array(da)\n",
    "test = pd.DataFrame(nparr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5614e4d061ba943"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.to_csv('test_idx2graph.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d896a04818fc939"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test_idx2graph=pd.read_csv('test_idx2graph.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b15e31d7081b41fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np_test_idx2graph=df_test_idx2graph.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "404867e3115843f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ec806e6dbb9fb3e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def load_word_vec(path, word2idx=None, embed_dim=300):\n",
    "    fin = open(path, 'r', encoding='utf8', newline='\\n', errors='ignore')\n",
    "    word_vec = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split()\n",
    "        word, vec = ' '.join(tokens[:-embed_dim]), tokens[-embed_dim:]\n",
    "        if word in word2idx.keys():\n",
    "            word_vec[word] = np.array(vec, dtype=np.float32)\n",
    "    return word_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:47.442771318Z",
     "start_time": "2024-02-10T19:48:47.286277929Z"
    }
   },
   "id": "9cf45baec8e2bdc1"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "def build_embedding_matrix(word2idx, embed_dim=300):\n",
    "    embedding_matrix = np.zeros((len(word2idx), embed_dim))\n",
    "    embedding_matrix[1, :] = np.random.uniform(-1/np.sqrt(embed_dim), 1/np.sqrt(embed_dim), (1, embed_dim))\n",
    "\n",
    "    glob_vector='./glove.840B.300d.txt'\n",
    "    word_vec = load_word_vec(glob_vector, word2idx=word2idx, embed_dim=embed_dim)\n",
    "\n",
    "    for word, i in word2idx.items():\n",
    "        vec = word_vec.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_matrix[i] = vec\n",
    "    return embedding_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:48:49.775299503Z",
     "start_time": "2024-02-10T19:48:47.940056352Z"
    }
   },
   "id": "3c2cc7faf4deb8a4"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "embedding_matrix = build_embedding_matrix(tokenizer.word2idx, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:49:43.722322972Z",
     "start_time": "2024-02-10T19:48:49.776894746Z"
    }
   },
   "id": "aeb509f01431e26d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-7.96900019e-02 -2.29049996e-01  8.03659976e-01 -7.88649976e-01\n",
      "  -4.05669987e-01 -1.57159999e-01 -4.23020005e-01  6.40810013e-01\n",
      "  -1.32149994e-01 -1.41090000e+00  7.31180012e-01 -3.73910010e-01\n",
      "  -3.64219993e-01  2.41989996e-02 -2.43589997e-01  1.01400006e+00\n",
      "   6.51760027e-04 -8.95370007e-01  8.05400014e-01 -7.31009990e-02\n",
      "   2.02570006e-01  5.95529974e-01 -3.49709997e-03 -2.81260014e-01\n",
      "   5.86310029e-01 -1.71149999e-01  1.24279998e-01  5.33919990e-01\n",
      "   4.82890010e-01  3.69890004e-01 -9.11509991e-02 -2.38739997e-01\n",
      "   3.88639987e-01 -1.64030001e-01 -8.57450008e-01  1.89999998e-01\n",
      "   4.14499998e-01  3.59580010e-01 -1.87260006e-02  5.52129984e-01\n",
      "  -9.13309958e-03 -4.82039988e-01 -6.46849990e-01  6.17359996e-01\n",
      "  -2.71279991e-01  1.34590000e-01  9.47290003e-01 -4.29390013e-01\n",
      "  -3.24620008e-01 -8.84660035e-02  3.73369992e-01  2.90619999e-01\n",
      "  -7.44110020e-03  1.98400006e-01 -4.26860005e-01 -7.12940022e-02\n",
      "  -4.34430018e-02 -3.30260000e-03 -1.05190001e-01  2.08849996e-01\n",
      "  -3.02170008e-01  2.73660004e-01 -3.56020004e-01 -8.91430020e-01\n",
      "   2.85609990e-01 -1.16559997e-01  2.24600002e-01 -2.15610005e-02\n",
      "  -1.62189994e-02 -9.62670028e-01  8.52389991e-01 -1.27139997e+00\n",
      "  -8.42899978e-01  2.59469986e-01  1.00740001e-01 -1.25300005e-01\n",
      "   1.61240008e-02  1.24880001e-01  1.64130002e-01 -4.60280001e-01\n",
      "   3.28249991e-01 -5.13670027e-01 -1.64560005e-01  5.64100027e-01\n",
      "   9.25619975e-02  1.11960006e+00  1.59360006e-01  6.61750019e-01\n",
      "  -1.00680006e+00 -8.61620009e-02  1.78470001e-01 -4.66439992e-01\n",
      "   1.26719996e-01  3.17860007e-01 -2.55329996e-01  7.35019982e-01\n",
      "  -1.07190004e-02  5.43410005e-03 -1.30190002e-02  6.02289975e-01\n",
      "   6.18459992e-02  6.10259995e-02  7.57470012e-01  6.87699974e-01\n",
      "   2.68869996e-02 -3.69179994e-01 -1.76280007e-01 -7.76139975e-01\n",
      "  -6.99349999e-01  5.39059997e-01  9.77630019e-02 -2.36479998e-01\n",
      "  -2.32170001e-01 -3.56180012e-01  4.99420017e-02 -4.83070016e-02\n",
      "  -7.12759972e-01 -8.04979980e-01 -4.97000013e-03 -1.49759993e-01\n",
      "   5.12740016e-01 -3.06589991e-01  1.23319998e-01  4.62949991e-01\n",
      "   5.15160024e-01 -1.13730001e+00 -5.71259975e-01  5.13499975e-01\n",
      "   2.91040003e-01 -8.63470018e-01  4.46130008e-01 -8.16579998e-01\n",
      "  -2.96719998e-01 -7.13970006e-01 -3.30709994e-01 -1.25729993e-01\n",
      "  -1.62530005e-01  3.12730014e-01 -5.93670011e-01 -3.31499986e-02\n",
      "   1.24049997e+00  2.64560014e-01  1.09889999e-01 -3.38820010e-01\n",
      "   2.66380012e-01  4.90569994e-02 -3.69590014e-01 -4.05919999e-01\n",
      "  -2.27579996e-01  6.04499996e-01 -3.76289994e-01  2.42190003e-01\n",
      "   2.77330011e-01 -6.31020010e-01  2.68669993e-01  7.70979971e-02\n",
      "   4.14189994e-01 -1.22649997e-01 -1.04419999e-01  6.55399978e-01\n",
      "  -2.83479989e-01  1.61199998e-02 -1.10859998e-01  3.89889985e-01\n",
      "   9.81209993e-01  1.38370001e+00 -4.86730009e-01  1.92530006e-01\n",
      "  -8.32249999e-01 -6.11029983e-01 -1.31009996e-01  1.01659996e-02\n",
      "   2.18250006e-01  8.06339979e-01  4.81110007e-01 -3.15939993e-01\n",
      "   1.04020000e-01 -6.09650016e-01 -4.22589988e-01 -2.68949986e-01\n",
      "  -4.35220003e-01  6.28650010e-01  9.10430029e-02 -5.99809997e-02\n",
      "   2.85019994e-01 -3.16210002e-01  3.69369984e-02  1.37720004e-01\n",
      "  -3.00150007e-01  3.74150008e-01  3.32529992e-01 -1.47450000e-01\n",
      "   1.42100006e-01 -4.17230010e-01 -8.81190002e-02 -5.23909986e-01\n",
      "   1.97490007e-02  1.00919998e+00  6.74700022e-01 -7.09840000e-01\n",
      "  -4.41309988e-01  1.95390005e-02 -1.31799996e-01 -1.10639997e-01\n",
      "  -5.71169972e-01  1.45439997e-01 -5.47140002e-01 -2.47940004e-01\n",
      "   6.47689998e-01  8.39430019e-02  6.75390005e-01  6.38830006e-01\n",
      "   9.72769980e-04  7.06080019e-01 -1.93770006e-01 -5.97440004e-01\n",
      "   4.86400008e-01 -5.67389987e-02  2.63209999e-01  6.78799972e-02\n",
      "  -1.27969995e-01  7.25879967e-02 -2.06070006e-01  2.81309992e-01\n",
      "   8.00149977e-01 -4.66049999e-01  1.95309997e-01 -3.62269998e-01\n",
      "  -2.09490001e-01 -1.13070004e-01  4.25399989e-01  1.02860004e-01\n",
      "  -2.81949997e-01 -1.15699999e-01  4.70330000e-01  3.17090005e-01\n",
      "   3.31369996e-01 -1.45310000e-01 -1.09180003e-01 -2.33740002e-01\n",
      "  -1.98970005e-01  1.26929998e-01 -3.74700017e-02 -4.53090012e-01\n",
      "  -3.49720001e-01 -3.38200003e-01  7.04069972e-01 -1.05499998e-01\n",
      "   7.85430014e-01  3.49630006e-02 -6.87590003e-01  7.45360017e-01\n",
      "   2.54250001e-02 -2.09189996e-01 -2.26909993e-03 -9.00219977e-01\n",
      "  -7.15340018e-01  6.52499974e-01 -1.05710000e-01 -4.97020006e-01\n",
      "  -3.84759992e-01 -3.92349988e-01  1.11599997e-01 -2.02169999e-01\n",
      "  -4.31629986e-01  4.26979989e-01  2.05449998e-01  4.03600007e-01\n",
      "  -8.69459987e-01  5.73660016e-01 -1.36830002e-01  6.57959998e-01\n",
      "   6.12829983e-01  2.73160011e-01 -7.35509992e-01 -7.01229990e-01\n",
      "  -3.90560001e-01 -4.38129991e-01 -3.21040004e-01 -6.18640006e-01\n",
      "  -7.43120015e-01 -4.93290007e-01 -7.08779991e-01 -3.56970012e-01\n",
      "   7.90950000e-01  6.22990012e-01 -3.60229999e-01  6.61780000e-01\n",
      "  -5.45889974e-01  1.06040001e-01  6.46570027e-01 -4.15910006e-01\n",
      "   1.42399997e-01 -5.17489985e-02  3.89250010e-01 -2.05219999e-01\n",
      "   2.68779993e-01 -8.35610032e-02  4.85320002e-01 -7.31299996e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:49:44.038104129Z",
     "start_time": "2024-02-10T19:49:44.015281459Z"
    }
   },
   "id": "8f6fd16c757e449a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "\n",
    "class TrainGraphFactoryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return \"./\"\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return os.path.join(self.root, \"train_processed\")\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train-graph.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        data_list = self.read_data()\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def read_data(self):\n",
    "        df_train = pd.read_csv(self.raw_paths[0])\n",
    "        all_data = []\n",
    "        for i in tqdm(range(df_train.shape[0])):\n",
    "            text = df_train.text[i].lower().replace(\"\\n\", \"\").strip()\n",
    "            doc = tokenizer.text_to_doc(text)\n",
    "            input_ids = tokenizer.doc_to_sequence(doc)\n",
    "            label = df_train.loc[i, [\"target\"]].to_list()\n",
    "\n",
    "            x = torch.tensor(input_ids.reshape((-1, 1)), dtype=torch.int32)\n",
    "            edge_index  = torch.tensor(train_idx2graph[i], dtype=torch.long)\n",
    "            y = torch.tensor(np.array(label), dtype=torch.float32).reshape(-1, 1)\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "            all_data.append(data)\n",
    "        return all_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:49:48.218965786Z",
     "start_time": "2024-02-10T19:49:48.018187662Z"
    }
   },
   "id": "7dbf33bdbc239cc"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "dataset = TrainGraphFactoryDataset(root='./')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:26.509083710Z",
     "start_time": "2024-02-10T19:49:49.278874659Z"
    }
   },
   "id": "a443b48f678c44ae"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train.csv'] ['./train_processed/train-graph.pt']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.raw_paths, dataset.processed_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:26.511194578Z",
     "start_time": "2024-02-10T19:50:26.508357281Z"
    }
   },
   "id": "6caa5444ee9f7eac"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackswan/anaconda3/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:301: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Data(x=[316326505, 1], edge_index=[2, 628944656], y=[434666, 1])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:26.529602691Z",
     "start_time": "2024-02-10T19:50:26.509576880Z"
    }
   },
   "id": "4e1feb5cfec709b2"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[209, 1], edge_index=[2, 396], y=[1, 1])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:26.620891235Z",
     "start_time": "2024-02-10T19:50:26.515213147Z"
    }
   },
   "id": "26107ba0224ae5bf"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[200000].y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.106993304Z",
     "start_time": "2024-02-10T19:50:26.530296920Z"
    }
   },
   "id": "6d22b72b45e187db"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "434666"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.108806810Z",
     "start_time": "2024-02-10T19:50:26.576809852Z"
    }
   },
   "id": "e27624f631db3d65"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347732 86934\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "ratio_cut= 0.8\n",
    "train_len = int(ratio_cut*len(dataset))\n",
    "train_dataset= dataset[:train_len]\n",
    "val_dataset= dataset[train_len:]\n",
    "print(len(train_dataset),len(val_dataset))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.358545656Z",
     "start_time": "2024-02-10T19:50:26.577718867Z"
    }
   },
   "id": "f95513799a83f2e5"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.415716320Z",
     "start_time": "2024-02-10T19:50:26.807826932Z"
    }
   },
   "id": "51220c1a5e683d32"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, TransformerConv, GATv2Conv, ChebConv, ResGatedGraphConv\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.loader import DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.416751355Z",
     "start_time": "2024-02-10T19:50:26.856394020Z"
    }
   },
   "id": "d1a8e7fc6d75e65c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackswan/anaconda3/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.418829482Z",
     "start_time": "2024-02-10T19:50:26.904073281Z"
    }
   },
   "id": "99d3f8e1bdd7e8e9"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-7.96900019e-02 -2.29049996e-01  8.03659976e-01 -7.88649976e-01\n",
      "  -4.05669987e-01 -1.57159999e-01 -4.23020005e-01  6.40810013e-01\n",
      "  -1.32149994e-01 -1.41090000e+00  7.31180012e-01 -3.73910010e-01\n",
      "  -3.64219993e-01  2.41989996e-02 -2.43589997e-01  1.01400006e+00\n",
      "   6.51760027e-04 -8.95370007e-01  8.05400014e-01 -7.31009990e-02\n",
      "   2.02570006e-01  5.95529974e-01 -3.49709997e-03 -2.81260014e-01\n",
      "   5.86310029e-01 -1.71149999e-01  1.24279998e-01  5.33919990e-01\n",
      "   4.82890010e-01  3.69890004e-01 -9.11509991e-02 -2.38739997e-01\n",
      "   3.88639987e-01 -1.64030001e-01 -8.57450008e-01  1.89999998e-01\n",
      "   4.14499998e-01  3.59580010e-01 -1.87260006e-02  5.52129984e-01\n",
      "  -9.13309958e-03 -4.82039988e-01 -6.46849990e-01  6.17359996e-01\n",
      "  -2.71279991e-01  1.34590000e-01  9.47290003e-01 -4.29390013e-01\n",
      "  -3.24620008e-01 -8.84660035e-02  3.73369992e-01  2.90619999e-01\n",
      "  -7.44110020e-03  1.98400006e-01 -4.26860005e-01 -7.12940022e-02\n",
      "  -4.34430018e-02 -3.30260000e-03 -1.05190001e-01  2.08849996e-01\n",
      "  -3.02170008e-01  2.73660004e-01 -3.56020004e-01 -8.91430020e-01\n",
      "   2.85609990e-01 -1.16559997e-01  2.24600002e-01 -2.15610005e-02\n",
      "  -1.62189994e-02 -9.62670028e-01  8.52389991e-01 -1.27139997e+00\n",
      "  -8.42899978e-01  2.59469986e-01  1.00740001e-01 -1.25300005e-01\n",
      "   1.61240008e-02  1.24880001e-01  1.64130002e-01 -4.60280001e-01\n",
      "   3.28249991e-01 -5.13670027e-01 -1.64560005e-01  5.64100027e-01\n",
      "   9.25619975e-02  1.11960006e+00  1.59360006e-01  6.61750019e-01\n",
      "  -1.00680006e+00 -8.61620009e-02  1.78470001e-01 -4.66439992e-01\n",
      "   1.26719996e-01  3.17860007e-01 -2.55329996e-01  7.35019982e-01\n",
      "  -1.07190004e-02  5.43410005e-03 -1.30190002e-02  6.02289975e-01\n",
      "   6.18459992e-02  6.10259995e-02  7.57470012e-01  6.87699974e-01\n",
      "   2.68869996e-02 -3.69179994e-01 -1.76280007e-01 -7.76139975e-01\n",
      "  -6.99349999e-01  5.39059997e-01  9.77630019e-02 -2.36479998e-01\n",
      "  -2.32170001e-01 -3.56180012e-01  4.99420017e-02 -4.83070016e-02\n",
      "  -7.12759972e-01 -8.04979980e-01 -4.97000013e-03 -1.49759993e-01\n",
      "   5.12740016e-01 -3.06589991e-01  1.23319998e-01  4.62949991e-01\n",
      "   5.15160024e-01 -1.13730001e+00 -5.71259975e-01  5.13499975e-01\n",
      "   2.91040003e-01 -8.63470018e-01  4.46130008e-01 -8.16579998e-01\n",
      "  -2.96719998e-01 -7.13970006e-01 -3.30709994e-01 -1.25729993e-01\n",
      "  -1.62530005e-01  3.12730014e-01 -5.93670011e-01 -3.31499986e-02\n",
      "   1.24049997e+00  2.64560014e-01  1.09889999e-01 -3.38820010e-01\n",
      "   2.66380012e-01  4.90569994e-02 -3.69590014e-01 -4.05919999e-01\n",
      "  -2.27579996e-01  6.04499996e-01 -3.76289994e-01  2.42190003e-01\n",
      "   2.77330011e-01 -6.31020010e-01  2.68669993e-01  7.70979971e-02\n",
      "   4.14189994e-01 -1.22649997e-01 -1.04419999e-01  6.55399978e-01\n",
      "  -2.83479989e-01  1.61199998e-02 -1.10859998e-01  3.89889985e-01\n",
      "   9.81209993e-01  1.38370001e+00 -4.86730009e-01  1.92530006e-01\n",
      "  -8.32249999e-01 -6.11029983e-01 -1.31009996e-01  1.01659996e-02\n",
      "   2.18250006e-01  8.06339979e-01  4.81110007e-01 -3.15939993e-01\n",
      "   1.04020000e-01 -6.09650016e-01 -4.22589988e-01 -2.68949986e-01\n",
      "  -4.35220003e-01  6.28650010e-01  9.10430029e-02 -5.99809997e-02\n",
      "   2.85019994e-01 -3.16210002e-01  3.69369984e-02  1.37720004e-01\n",
      "  -3.00150007e-01  3.74150008e-01  3.32529992e-01 -1.47450000e-01\n",
      "   1.42100006e-01 -4.17230010e-01 -8.81190002e-02 -5.23909986e-01\n",
      "   1.97490007e-02  1.00919998e+00  6.74700022e-01 -7.09840000e-01\n",
      "  -4.41309988e-01  1.95390005e-02 -1.31799996e-01 -1.10639997e-01\n",
      "  -5.71169972e-01  1.45439997e-01 -5.47140002e-01 -2.47940004e-01\n",
      "   6.47689998e-01  8.39430019e-02  6.75390005e-01  6.38830006e-01\n",
      "   9.72769980e-04  7.06080019e-01 -1.93770006e-01 -5.97440004e-01\n",
      "   4.86400008e-01 -5.67389987e-02  2.63209999e-01  6.78799972e-02\n",
      "  -1.27969995e-01  7.25879967e-02 -2.06070006e-01  2.81309992e-01\n",
      "   8.00149977e-01 -4.66049999e-01  1.95309997e-01 -3.62269998e-01\n",
      "  -2.09490001e-01 -1.13070004e-01  4.25399989e-01  1.02860004e-01\n",
      "  -2.81949997e-01 -1.15699999e-01  4.70330000e-01  3.17090005e-01\n",
      "   3.31369996e-01 -1.45310000e-01 -1.09180003e-01 -2.33740002e-01\n",
      "  -1.98970005e-01  1.26929998e-01 -3.74700017e-02 -4.53090012e-01\n",
      "  -3.49720001e-01 -3.38200003e-01  7.04069972e-01 -1.05499998e-01\n",
      "   7.85430014e-01  3.49630006e-02 -6.87590003e-01  7.45360017e-01\n",
      "   2.54250001e-02 -2.09189996e-01 -2.26909993e-03 -9.00219977e-01\n",
      "  -7.15340018e-01  6.52499974e-01 -1.05710000e-01 -4.97020006e-01\n",
      "  -3.84759992e-01 -3.92349988e-01  1.11599997e-01 -2.02169999e-01\n",
      "  -4.31629986e-01  4.26979989e-01  2.05449998e-01  4.03600007e-01\n",
      "  -8.69459987e-01  5.73660016e-01 -1.36830002e-01  6.57959998e-01\n",
      "   6.12829983e-01  2.73160011e-01 -7.35509992e-01 -7.01229990e-01\n",
      "  -3.90560001e-01 -4.38129991e-01 -3.21040004e-01 -6.18640006e-01\n",
      "  -7.43120015e-01 -4.93290007e-01 -7.08779991e-01 -3.56970012e-01\n",
      "   7.90950000e-01  6.22990012e-01 -3.60229999e-01  6.61780000e-01\n",
      "  -5.45889974e-01  1.06040001e-01  6.46570027e-01 -4.15910006e-01\n",
      "   1.42399997e-01 -5.17489985e-02  3.89250010e-01 -2.05219999e-01\n",
      "   2.68779993e-01 -8.35610032e-02  4.85320002e-01 -7.31299996e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:50:27.422203283Z",
     "start_time": "2024-02-10T19:50:26.904997779Z"
    }
   },
   "id": "cec664fc9ca8d04a"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10867it [03:09, 57.25it/s]\n",
      "2717it [00:45, 59.14it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = []\n",
    "invalid = []\n",
    "for i, data in tqdm(enumerate(train_loader)):\n",
    "    try:\n",
    "        if data.num_nodes > data.edge_index.max():\n",
    "            valid.append(data)\n",
    "        else:\n",
    "            invalid.append(i)\n",
    "    except ValueError as ie:\n",
    "        print('error in train edge index')\n",
    "\n",
    "\n",
    "val_valid = []\n",
    "val_invalid = []\n",
    "for i, data in tqdm(enumerate(val_loader)):\n",
    "    try:\n",
    "        if data.num_nodes>data.edge_index.max():\n",
    "            val_valid.append(data)\n",
    "        else:\n",
    "            val_invalid.append(i)\n",
    "    except IndexError as ie:\n",
    "        print('error in val edge index')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:54:22.747257559Z",
     "start_time": "2024-02-10T19:50:26.947944608Z"
    }
   },
   "id": "1bb487921a91bd38"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "48.651881844115216"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(valid)/len(train_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:54:22.748661083Z",
     "start_time": "2024-02-10T19:54:22.716535787Z"
    }
   },
   "id": "e2a79e6d80ea3b6d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "51.34811815588479"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(invalid)/len(train_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:54:22.749495283Z",
     "start_time": "2024-02-10T19:54:22.717517702Z"
    }
   },
   "id": "f88c89f1ed7b008b"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "48.141332351858665"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(val_valid)/len(val_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:54:23.396116335Z",
     "start_time": "2024-02-10T19:54:22.718202974Z"
    }
   },
   "id": "1a87477394de99d4"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "51.858667648141335"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(val_invalid)/len(val_loader))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:54:23.397745377Z",
     "start_time": "2024-02-10T19:54:22.759989646Z"
    }
   },
   "id": "fdb620f65535eabd"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "\n",
    "\n",
    "class FeedbackModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix):\n",
    "\n",
    "        super(FeedbackModel, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float), freeze=False)\n",
    "        # GCNConv SAGEConv ResGatedGraphConv GraphConv(300, 128) \n",
    "        # TransformerConv GATv2Conv GATConv(300, 128, heads=4) ChebConv(300, 128, K=2)\n",
    "        # GCNConv SAGEConv ResGatedGraphConv GraphConv(128, 64) \n",
    "        # TransformerConv  GATv2Conv GATConv(4*128, 64) ChebConv(128, 64, K=2)\n",
    "        #         self.gru = nn.GRU(256, 256, num_layers=1, \n",
    "        #                           dropout=0, batch_first=True,\n",
    "        #                           bidirectional=False)          # RNN, GRU\n",
    "        # output: (N, L, DHout), D = 2 if bidirectional=True otherwise 1\n",
    "        # h_n: (Dnum_layers, N, Hout)\n",
    "        self.gc1   = GATv2Conv(300, 128, heads=4)\n",
    "        #self.gc1   = GraphSAGE (300,128, 32)\n",
    "        self.pool1 = pyg_nn.TopKPooling(128, ratio=0.8)\n",
    "        self.gc2   = GCNConv(128, 64)\n",
    "        self.pool2 = pyg_nn.TopKPooling(64, ratio=0.8)\n",
    "        self.lin1  = nn.Linear(64, 32)\n",
    "        self.lin2  = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data_list = [Data(x=x_, edge_index=data.edge_index, sample_batched=data.batch) for x_ in (data.x)]\n",
    "        batch = Batch.from_data_list(data_list)\n",
    "        print('(Data List Loaded)')\n",
    "        x = batch.x\n",
    "        sample_batch=batch.sample_batched\n",
    "        print('(squeeze passed)')\n",
    "        #x = torch.clamp(x, 0, self.embed.num_embeddings - 1)\n",
    "        print('(embed 1 pre-Loaded')\n",
    "        x = self.embed(x)\n",
    "    \n",
    "        print('(Layer 1 pre-Loaded)')\n",
    "        x = F.relu(self.gc1(x, edge_index=batch.edge_index))\n",
    "        print('(Layer 1 Loaded)')\n",
    "        x, edge_index, edge_attr, batch2, perm, score = self.pool1(x, batch.edge_index, None, sample_batch)\n",
    "        x1 = torch.cat([pyg_nn.global_max_pool(x, batch2), pyg_nn.global_mean_pool(x, batch2)], dim=1)\n",
    "\n",
    "        x = F.relu(self.gc2(x, batch.edge_index))\n",
    "        print('(Layer 2 Loaded)')\n",
    "        x, edge_index, edge_attr, batch2, perm, score = self.pool2(x, data.edge_index, None, sample_batch)\n",
    "        x2 = torch.cat([pyg_nn.global_max_pool(x, batch2), pyg_nn.global_mean_pool(x, batch2)], dim=1)\n",
    "\n",
    "        x = x1 + x2\n",
    "        x = F.relu(self.lin1(x))\n",
    "        print('(Layer 3 Loaded)')\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        output = F.relu(self.lin2(x))\n",
    "        return output\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:01:37.138171004Z",
     "start_time": "2024-02-10T20:01:36.809196935Z"
    }
   },
   "id": "737cff2ae4ddf4b9"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "FeedbackModel(\n  (embed): Embedding(2, 300)\n  (gc1): GATv2Conv(300, 128, heads=4)\n  (pool1): TopKPooling(128, ratio=0.8, multiplier=1.0)\n  (gc2): GCNConv(128, 64)\n  (pool2): TopKPooling(64, ratio=0.8, multiplier=1.0)\n  (lin1): Linear(in_features=64, out_features=32, bias=True)\n  (lin2): Linear(in_features=32, out_features=1, bias=True)\n)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedbackModel(embedding_matrix)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:01:41.712968180Z",
     "start_time": "2024-02-10T20:01:41.467844048Z"
    }
   },
   "id": "326ac578eea20f61"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "MSELoss()"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=6)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T20:01:43.839895136Z",
     "start_time": "2024-02-10T20:01:43.628015307Z"
    }
   },
   "id": "d6aebbf0337cc59"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 in progress...\n",
      "train computing\n",
      "in train loop\n",
      "(Data List Loaded)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m sample_batched \u001B[38;5;241m=\u001B[39m sample_batched\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(sample_batched)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputs loaded\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m label \u001B[38;5;241m=\u001B[39m sample_batched\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[49], line 34\u001B[0m, in \u001B[0;36mFeedbackModel.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     32\u001B[0m x \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mx\n\u001B[1;32m     33\u001B[0m sample_batch\u001B[38;5;241m=\u001B[39mbatch\u001B[38;5;241m.\u001B[39msample_batched\n\u001B[0;32m---> 34\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(squeeze passed)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m#x = torch.clamp(x, 0, self.embed.num_embeddings - 1)\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "for epoch_num in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss_train = 0\n",
    "    print(f'epoch: {epoch_num} in progress...')\n",
    "    print(f'train computing')\n",
    "    \n",
    "    for sample_batched in valid:\n",
    "        print('in train loop')\n",
    "        sample_batched = sample_batched.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sample_batched)\n",
    "        print('outputs loaded')\n",
    "        label = sample_batched.y.to(device)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        total_loss_train += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    \n",
    "    print(f'train evaluating')\n",
    "    with torch.no_grad():\n",
    "        for sample_batched in val_valid:\n",
    "                sample_batched = sample_batched.to(device)\n",
    "                outputs = model(sample_batched)\n",
    "                label = sample_batched.y.to(device)\n",
    "                loss = criterion(outputs, label)\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "    scheduler.step(total_loss_val / len(val_dataset))\n",
    "\n",
    "    print(f'Epoch: %02.0f ended | Train Loss: {total_loss_train / len(train_dataset): .3f} | Val Loss: {total_loss_val / len(val_dataset): .3f}' % (epoch_num + 1))\n",
    "    total_loss.append([total_loss_train / len(train_dataset), total_loss_val / len(val_dataset)])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T19:56:09.845700169Z",
     "start_time": "2024-02-10T19:55:44.818449222Z"
    }
   },
   "id": "9f8e679ac0c6a8be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1537f9a68800e3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24cea7a9cc91f2ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4dcee45a532fcbda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
